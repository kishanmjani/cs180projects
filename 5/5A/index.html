<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>Project 5</title>

    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;600&family=Merriweather:wght@300;400;700&display=swap" rel="stylesheet">

    <script defer src="https://use.fontawesome.com/releases/v5.7.2/js/all.js"
        integrity="sha384-0pzryjIRos8mFBWMzSSZApWtPl/5++eIfzYmTgBBmXYdhvxPc+XcFEk+zJwDgWbP"
        crossorigin="anonymous"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
    <header>
        <h1>Project 5A: The Power of Diffusion Models</h1>
        <p>Kishan Jani</p>
    </header>

    <div class="container">

        <!-- Contents -->
        <main>
            </section>
            <section id="part 0">
                <h2>Part 5A 0: Setup</h2>
                <p>
                    We will use the <code> DeepFloydIF </code> diffusion model. We use a random seed of <code> seed = 10</code>, 
                    here and throughout the project. In this part, we simply test out the model, generating images 
                    for 3 text prompts with captions. We do this across different values of <code> num_inference_steps </code>.
                </p>
                <br>
                To see the images generated, click on the following link: 
                <br>
                <a href="./0/index.html">5A Part 0 Results</a>
            </section>

            <section id="part 1.1">
                <h2>Part 5A 1.1: Implementing the Forward Porcess</h2>
                <h3> Overview </h3>
                <p>
                    The forward process is defined by 
                    \[ x_t = \sqrt{\bar{\alpha}_t}x_0 + \sqrt{1 - \bar{\alpha}_t}\varepsilon  \]
                    where \( \varepsilon \sim N(0,1) \). Here \(x_0\) is the clean image, the noisy image 
                    generated is \( x_t \), so we really are making the noisy image by sampling from a Gaussian 
                    of mean \( \sqrt{\bar{\alpha}_t} x_0\) and variance \( 1- \bar{\alpha}_t \). 

                    We perform the process on a test image of the campanile shown below, which we will resize 
                    to \( 64 \times 64 \). 
                </p>
                <h3> Results </h3>
                <p> To see results for \( t\in [250,500,750] \), click the link below: </p>

                <a href="./1.1/index.html">5A Part 1.1 Results</a>
                  
            </section>


            <section id="part 1.2">
                <h2>Part 5A 1.2: Gaussian Blur Denoising</h2>
                <h3> Overview </h3>
                <p>
                    We naively denoise images by blurring them with a fixed Gaussian. We use
                    <code>kernel_size = 5</code> and <code> sigma = 1.5 </code> for the Gaussian. We do
                    this for the noise levels seen before. 
                </p>
                <h3> Results </h3>
                <p> To see results for \( t\in [250,500,750] \), click the link below: </p>

                <a href="./1.2/index.html">5A Part 1.2 Results</a>
                  
            </section>

            <section id="part 1.3">
                <h2>Part 5A 1.3: One-Step Denoising</h2>
                <h3> Overview </h3>
                <p>
                    Now, we'll use a pretrained diffusion model to denoise. The actual denoiser
                     can be found at <code>stage_1.unet</code>. This is a UNet that has already been trained on 
                     a very, very large dataset of pairs of images \( x_0, x_t \). We can use it to 
                     recover Gaussian noise from the image. Then, we can remove this noise to recover 
                     (something close to) the original image. To compute \(x_0\) from \(x_t\), we use 
                     \[ \hat{x}_0 = \frac{1}{\sqrt{\bar{\alpha}_t}} [x_t - \sqrt{1 - \bar{\alpha}_t} \varepsilon_\theta(x_t,t)],\]
                     where \(\varepsilon_\theta(\cdot,\cdot)\) is the noise predicted by our model for a given noisy image \(x_t\)
                     and corresponding noise level \(t\).  
                </p>
                <h3> Results </h3>
                <p> To see results for \( t\in [250,500,750] \), click the link below: </p>

                <a href="./1.3/index.html">5A Part 1.3 Results</a>
                  
            </section>

            <section id="part 1.4">
                <h2>Part 5A 1.4: Iterative Denoising</h2>
                <h3> Overview </h3>
                <p>
                    Blurb
                </p>
                <h3> Results </h3>
                <p> To see results, click the link below: </p>

                <a href="./1.4/index.html">5A Part 1.4 Results</a>
                  
            </section>

            <section id="part 1.5">
                <h2>Part 5A 1.5: Diffusion Model Sampling</h2>
                <h3> Overview </h3>
                <p>
                    We "generate" images using the Diffusion Model by feeding random noise into the iterative 
                    denoiser, using <code> i_start = 0 </code>. 
                </p>
                <h3> Results </h3>
                <p> To see results, click the link below: </p>

                <a href="./1.5/index.html">5A Part 1.5 Results</a>
                  
            </section>

            <section id="part 1.6">
                <h2>Part 5A 1.6: Classifier Free Guidance (CFG)</h2>
                <h3> Overview </h3>
                <p>
                    Blurb
                </p>
                <h3> Results </h3>
                <p> To see results, click the link below: </p>

                <a href="./1.6/index.html">5A Part 1.6 Results</a>
                  
            </section>

            <section id="part 1.7">
                <h2>Part 5A 1.7: Image-to-Image translation</h2>
                <h3> Overview </h3>
                <p>
                    Blurb
                </p>
                <h3> Results </h3>
                <p> To see results, click the link below: </p>

                <a href="./1.7/index.html">5A Part 1.7 Results</a>
                  
            </section>

        </main>
    </div>

</body>

</html>
